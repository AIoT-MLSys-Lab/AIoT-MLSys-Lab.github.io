"use strict";(self.webpackChunklabwebsite=self.webpackChunklabwebsite||[]).push([[160],{876:function(e,i,t){var s=t(8316),n=t(184),r={height:"300px",color:"#fff",lineHeight:"160px",textAlign:"center",background:"#364d79"};i.Z=function(){return(0,n.jsxs)(s.Z,{autoplay:!0,children:[(0,n.jsx)("div",{children:(0,n.jsx)("h3",{style:r,children:"1"})}),(0,n.jsx)("div",{children:(0,n.jsx)("h3",{style:r,children:"2"})}),(0,n.jsx)("div",{children:(0,n.jsx)("h3",{style:r,children:"3"})}),(0,n.jsx)("div",{children:(0,n.jsx)("h3",{style:r,children:"4"})})]})}},7160:function(e,i,t){t.r(i),t.d(i,{default:function(){return r}});t(2791),t(876);var s=t(4996),n=t(184);var r=function(){return(0,n.jsxs)("div",{className:"project_container",children:[(0,n.jsx)("div",{className:"project_title",children:"Mercury: Efficient On-Device Distributed DNN Training via Stochastic Importance Sampling"}),(0,n.jsx)("div",{className:"project_conference",children:"SenSys'21"}),(0,n.jsx)("div",{className:"project_members",children:"Xiao Zeng, Ming Yan, and Mi Zhang."}),(0,n.jsxs)("div",{className:"project_buttons",children:[(0,n.jsxs)("a",{href:"https://mi-zhang.github.io/papers/2021_SenSys_Mercury.pdf",className:"project_button",children:[(0,n.jsx)("svg",{t:"1687728426228",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2399",width:"16",height:"16",children:(0,n.jsx)("path",{d:"M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z",fill:"#ffffff","p-id":"2400"})}),"\xa0Paper"]}),(0,n.jsx)(s.Z,{inproceeding:"@inproceedings{mercury2021sensys,",title:"title={{Mercury: Efficient On-Device Distributed DNN Training via Stochastic Importance Sampling}},",author:"author={Zeng, Xiao and Yan, Ming and Zhang, Mi},",booktitle:"booktitle={ACM Conference on Embedded Networked Sensor Systems (SenSys)},",year:"year={2021}"})]}),(0,n.jsx)("div",{className:"project_collection",children:(0,n.jsx)("div",{children:(0,n.jsx)("img",{src:"./images/projects/Mercury_in.svg",alt:""})})}),(0,n.jsxs)("div",{className:"project_abstract",children:[(0,n.jsx)("div",{className:"project_abstract_title",children:"Abstract"}),(0,n.jsx)("div",{className:"project_abstract_content",children:"As intelligence is moving from data centers to the edges, intelligent edge devices such as smartphones, drones, robots, and smart IoT devices are equipped with the capability to altogether train a deep learning model on the devices from the data collected by themselves. Despite its considerable value, the key bottleneck of making on-device distributed training practically useful in realworld deployments is that they consume a significant amount of training time under wireless networks with constrained bandwidth. To tackle this critical bottleneck, we present Mercury, an importance sampling-based framework that enhances the training efficiency of on-device distributed training without compromising the accuracies of the trained models. The key idea behind the design of Mercury is to focus on samples that provide more important information in each training iteration. In doing this, the training efficiency of each iteration is improved. As such, the total number of iterations can be considerably reduced so as to speed up the overall training process. We implemented Mercury and deployed it on a self-developed testbed. We demonstrate its effectiveness and show that Mercury consistently outperforms two status quo frameworks on six commonly used datasets across tasks in image classification, speech recognition, and natural language processing."})]})]})}},4996:function(e,i,t){t.d(i,{Z:function(){return l}});var s=t(9439),n=t(2791),r=t(6913),c=t(7309),a=t(184),l=function(e){var i=(0,n.useState)(!1),t=(0,s.Z)(i,2),l=t[0],o=t[1],d=function(){o(!1)};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsxs)("button",{href:"",className:"project_button",onClick:function(){o(!0)},children:[(0,a.jsx)("svg",{t:"1687730915571",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2419",width:"16",height:"16",children:(0,a.jsx)("path",{d:"M313.6 170.666667h469.333333c27.733333 0 42.666667 14.933333 42.666667 42.666666v512c0 8.533333-4.266667 17.066667-10.666667 23.466667l-36.266666 36.266667c-2.133333 2.133333-6.4 4.266667-6.4 2.133333-2.133333 0-2.133333-4.266667-2.133334-6.4v-539.733333c0-4.266667-2.133333-6.4-4.266666-10.666667s-6.4-4.266667-10.666667-4.266667h-398.933333c-8.533333 0-17.066667 4.266667-23.466667 10.666667l-36.266667 36.266667c-2.133333 2.133333-4.266667 6.4-2.133333 6.4 0 2.133333 4.266667 2.133333 6.4 2.133333h398.933333c4.266667 0 6.4 2.133333 10.666667 4.266667s4.266667 6.4 4.266667 10.666666v539.733334c0 4.266667-2.133333 6.4-4.266667 10.666666s-6.4 4.266667-10.666667 4.266667H213.333333c-4.266667 0-6.4-2.133333-10.666666-4.266667s-4.266667-6.4-4.266667-10.666666v-554.666667c0-8.533333 4.266667-17.066667 10.666667-23.466667l78.933333-78.933333c6.4-4.266667 14.933333-8.533333 25.6-8.533333z","p-id":"2420",fill:"#ffffff"})}),"\xa0BibTex"]}),(0,a.jsx)(r.Z,{title:"BibTex",open:l,onCancel:d,width:1e3,footer:[(0,a.jsx)(c.ZP,{onClick:d,children:"Return"},"back")],children:(0,a.jsxs)("div",{className:"popModalBG",children:[(0,a.jsx)("p",{children:e.inproceeding}),(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.title]}),(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.author]}),e.booktitle&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.booktitle]}),e.journal&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.journal]}),e.volume&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.volume]}),e.number&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.number]}),e.pages&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.pages]}),(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.year]}),e.eprint&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.eprint]}),e.archivePrefix&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.archivePrefix]}),e.primaryClass&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.primaryClass]}),e.numpages&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.numpages]}),e.address&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.address]}),e.location&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.location]}),e.publisher&&(0,a.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.publisher]}),(0,a.jsx)("p",{children:"}"})]})})]})}}}]);
//# sourceMappingURL=160.5a5ba683.chunk.js.map