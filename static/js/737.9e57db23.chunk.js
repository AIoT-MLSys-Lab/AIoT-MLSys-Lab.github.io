"use strict";(self.webpackChunklabwebsite=self.webpackChunklabwebsite||[]).push([[737],{876:function(e,s,i){var n=i(8316),t=i(184),a={height:"300px",color:"#fff",lineHeight:"160px",textAlign:"center",background:"#364d79"};s.Z=function(){return(0,t.jsxs)(n.Z,{autoplay:!0,children:[(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:a,children:"1"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:a,children:"2"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:a,children:"3"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:a,children:"4"})})]})}},737:function(e,s,i){i.r(s),i.d(s,{default:function(){return a}});i(2791),i(876);var n=i(4996),t=i(184);var a=function(){return(0,t.jsxs)("div",{className:"project_container",children:[(0,t.jsx)("div",{className:"project_title",children:"Famba-V: Fast Vision Mamba with Cross-Layer Token Fusion"}),(0,t.jsx)("div",{className:"project_conference",children:"ECCV'24 Workshop on Computational Aspects of Deep Learning"}),(0,t.jsx)("div",{className:"project_members",children:"Hui Shen, Zhongwei Wan, Xin Wang, and Mi Zhang."}),(0,t.jsxs)("div",{className:"project_buttons",children:[(0,t.jsxs)("a",{href:"https://mi-zhang.github.io/papers/2024_ECCVW_Famba-V.pdf",className:"project_button",children:[(0,t.jsx)("svg",{t:"1687728426228",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2399",width:"16",height:"16",children:(0,t.jsx)("path",{d:"M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z",fill:"#ffffff","p-id":"2400"})}),"\xa0Paper"]}),(0,t.jsx)(n.Z,{inproceeding:"@inproceedings{fambav2024eccvw,",title:"title={Famba-V: Fast Vision Mamba with Sparse Fusion-based Visual Representation},",author:"author={Shen, Hui and Wan, Zhongwei and Wang, Xin and Zhang, Mi},",booktitle:"booktitle={European Conference on Computer Vision (ECCV) Workshop on Computational Aspects of Deep Learning},",year:"year={2024}"})]}),(0,t.jsx)("div",{className:"project_collection",children:(0,t.jsx)("div",{children:(0,t.jsx)("img",{src:"./images/projects/FambaV_in.png",alt:"",className:"project_collection_img"})})}),(0,t.jsxs)("div",{className:"project_abstract",children:[(0,t.jsx)("div",{className:"project_abstract_title",children:"Abstract"}),(0,t.jsx)("div",{className:"project_abstract_content",children:"Mamba and Vision Mamba (Vim) models have shown their potential as an alternative to methods based on Transformer architecture. This work introduces Fast Mamba for Vision (Famba-V), a cross-layer token fusion technique to enhance the training efficiency of Vim models. The key idea of Famba-V is to identify and fuse similar tokens across different Vim layers based on a suit of cross-layer strategies instead of simply applying token fusion uniformly across all the layers that existing works propose. We evaluate the performance of Famba-V on CIFAR-100. Our results show that Famba-V is able to enhance the training efficiency of Vim models by reducing both training time and peak memory usage during training. Moreover, the proposed cross-layer strategies allow Famba-V to deliver superior accuracy-efficiency trade-offs. These results all together demonstrate Famba-V as a promising efficiency enhancement technique for Vim models."})]})]})}},4996:function(e,s,i){i.d(s,{Z:function(){return c}});var n=i(9439),t=i(2791),a=i(6913),r=i(7309),o=i(184),c=function(e){var s=(0,t.useState)(!1),i=(0,n.Z)(s,2),c=i[0],l=i[1],h=function(){l(!1)};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)("button",{href:"",className:"project_button",onClick:function(){l(!0)},children:[(0,o.jsx)("svg",{t:"1687730915571",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2419",width:"16",height:"16",children:(0,o.jsx)("path",{d:"M313.6 170.666667h469.333333c27.733333 0 42.666667 14.933333 42.666667 42.666666v512c0 8.533333-4.266667 17.066667-10.666667 23.466667l-36.266666 36.266667c-2.133333 2.133333-6.4 4.266667-6.4 2.133333-2.133333 0-2.133333-4.266667-2.133334-6.4v-539.733333c0-4.266667-2.133333-6.4-4.266666-10.666667s-6.4-4.266667-10.666667-4.266667h-398.933333c-8.533333 0-17.066667 4.266667-23.466667 10.666667l-36.266667 36.266667c-2.133333 2.133333-4.266667 6.4-2.133333 6.4 0 2.133333 4.266667 2.133333 6.4 2.133333h398.933333c4.266667 0 6.4 2.133333 10.666667 4.266667s4.266667 6.4 4.266667 10.666666v539.733334c0 4.266667-2.133333 6.4-4.266667 10.666666s-6.4 4.266667-10.666667 4.266667H213.333333c-4.266667 0-6.4-2.133333-10.666666-4.266667s-4.266667-6.4-4.266667-10.666666v-554.666667c0-8.533333 4.266667-17.066667 10.666667-23.466667l78.933333-78.933333c6.4-4.266667 14.933333-8.533333 25.6-8.533333z","p-id":"2420",fill:"#ffffff"})}),"\xa0BibTex"]}),(0,o.jsx)(a.Z,{title:"BibTex",open:c,onCancel:h,width:1e3,footer:[(0,o.jsx)(r.ZP,{onClick:h,children:"Return"},"back")],children:(0,o.jsxs)("div",{className:"popModalBG",children:[(0,o.jsx)("p",{children:e.inproceeding}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.title]}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.author]}),e.booktitle&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.booktitle]}),e.journal&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.journal]}),e.volume&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.volume]}),e.number&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.number]}),e.pages&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.pages]}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.year]}),e.eprint&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.eprint]}),e.archivePrefix&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.archivePrefix]}),e.primaryClass&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.primaryClass]}),e.numpages&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.numpages]}),e.address&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.address]}),e.location&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.location]}),e.publisher&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.publisher]}),(0,o.jsx)("p",{children:"}"})]})})]})}}}]);
//# sourceMappingURL=737.9e57db23.chunk.js.map