"use strict";(self.webpackChunklabwebsite=self.webpackChunklabwebsite||[]).push([[754],{876:function(e,s,i){var n=i(8316),t=i(184),r={height:"300px",color:"#fff",lineHeight:"160px",textAlign:"center",background:"#364d79"};s.Z=function(){return(0,t.jsxs)(n.Z,{autoplay:!0,children:[(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:r,children:"1"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:r,children:"2"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:r,children:"3"})}),(0,t.jsx)("div",{children:(0,t.jsx)("h3",{style:r,children:"4"})})]})}},2754:function(e,s,i){i.r(s),i.d(s,{default:function(){return r}});i(2791),i(876);var n=i(4996),t=i(184);var r=function(){return(0,t.jsxs)("div",{className:"project_container",children:[(0,t.jsx)("div",{className:"project_title",children:"ETP: Learning Transferable ECG Representations via ECG-Text Pre-Training"}),(0,t.jsx)("div",{className:"project_conference",children:"ICASSP 2024"}),(0,t.jsx)("div",{className:"project_members",children:"Che Liu*, Zhongwei Wan*, Sibo Cheng, Mi Zhang, Rossella Arcucci"}),(0,t.jsxs)("div",{className:"project_buttons",children:[(0,t.jsxs)("a",{href:"https://mi-zhang.github.io/papers/2024_ICASSP_ETP.pdf",className:"project_button",children:[(0,t.jsx)("svg",{t:"1687728426228",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2399",width:"16",height:"16",children:(0,t.jsx)("path",{d:"M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z",fill:"#ffffff","p-id":"2400"})}),"\xa0Paper"]}),(0,t.jsx)(n.Z,{inproceeding:"@inproceedings{etp2024icassp,",title:"title = {ETP: Learning Transferable ECG Representations via ECG-Text Pre-Training},",author:"author = {Liu, Che and Wan, Zhongwei and Cheng, Sibo and Zhang, Mi and Arcucci, Rossella},",booktitle:"booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},",year:"year = {2024}"})]}),(0,t.jsx)("div",{className:"project_collection",children:(0,t.jsx)("div",{children:(0,t.jsx)("img",{src:"./images/projects/ETP.svg",alt:"",className:"project_collection_img"})})}),(0,t.jsxs)("div",{className:"project_abstract",children:[(0,t.jsx)("div",{className:"project_abstract_title",children:"Abstract"}),(0,t.jsx)("div",{className:"project_abstract_content",children:"In the domain of cardiovascular healthcare, the Electrocardiogram (ECG) serves as a critical, non-invasive diagnostic tool. Although recent strides in self-supervised learning (SSL) have been promising for ECG representation learning, these techniques often require annotated samples and struggle with classes not present in the fine-tuning stages. To address these limitations, we introduce ECG-Text Pre-training (ETP), an innovative framework designed to learn cross-modal representations that link ECG signals with textual reports. For the first time, this framework leverages the zero-shot classification task in the ECG domain. ETP employs an ECG encoder along with a pre-trained language model to align ECG signals with their corresponding textual reports. The proposed framework excels in both linear evaluation and zero-shot classification tasks, as demonstrated on the PTB-XL and CPSC2018 datasets, showcasing its ability for robust and generalizable cross-modal ECG feature learning."})]})]})}},4996:function(e,s,i){i.d(s,{Z:function(){return c}});var n=i(9439),t=i(2791),r=i(6913),a=i(7309),l=i(184),c=function(e){var s=(0,t.useState)(!1),i=(0,n.Z)(s,2),c=i[0],o=i[1],h=function(){o(!1)};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsxs)("button",{href:"",className:"project_button",onClick:function(){o(!0)},children:[(0,l.jsx)("svg",{t:"1687730915571",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2419",width:"16",height:"16",children:(0,l.jsx)("path",{d:"M313.6 170.666667h469.333333c27.733333 0 42.666667 14.933333 42.666667 42.666666v512c0 8.533333-4.266667 17.066667-10.666667 23.466667l-36.266666 36.266667c-2.133333 2.133333-6.4 4.266667-6.4 2.133333-2.133333 0-2.133333-4.266667-2.133334-6.4v-539.733333c0-4.266667-2.133333-6.4-4.266666-10.666667s-6.4-4.266667-10.666667-4.266667h-398.933333c-8.533333 0-17.066667 4.266667-23.466667 10.666667l-36.266667 36.266667c-2.133333 2.133333-4.266667 6.4-2.133333 6.4 0 2.133333 4.266667 2.133333 6.4 2.133333h398.933333c4.266667 0 6.4 2.133333 10.666667 4.266667s4.266667 6.4 4.266667 10.666666v539.733334c0 4.266667-2.133333 6.4-4.266667 10.666666s-6.4 4.266667-10.666667 4.266667H213.333333c-4.266667 0-6.4-2.133333-10.666666-4.266667s-4.266667-6.4-4.266667-10.666666v-554.666667c0-8.533333 4.266667-17.066667 10.666667-23.466667l78.933333-78.933333c6.4-4.266667 14.933333-8.533333 25.6-8.533333z","p-id":"2420",fill:"#ffffff"})}),"\xa0BibTex"]}),(0,l.jsx)(r.Z,{title:"BibTex",open:c,onCancel:h,width:1e3,footer:[(0,l.jsx)(a.ZP,{onClick:h,children:"Return"},"back")],children:(0,l.jsxs)("div",{className:"popModalBG",children:[(0,l.jsx)("p",{children:e.inproceeding}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.title]}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.author]}),e.booktitle&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.booktitle]}),e.journal&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.journal]}),e.volume&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.volume]}),e.number&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.number]}),e.pages&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.pages]}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.year]}),e.eprint&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.eprint]}),e.archivePrefix&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.archivePrefix]}),e.primaryClass&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.primaryClass]}),e.numpages&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.numpages]}),e.address&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.address]}),e.location&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.location]}),e.publisher&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.publisher]}),(0,l.jsx)("p",{children:"}"})]})})]})}}}]);
//# sourceMappingURL=754.1974e170.chunk.js.map