"use strict";(self.webpackChunklabwebsite=self.webpackChunklabwebsite||[]).push([[121],{876:function(e,i,t){var n=t(8316),l=t(184),s={height:"300px",color:"#fff",lineHeight:"160px",textAlign:"center",background:"#364d79"};i.Z=function(){return(0,l.jsxs)(n.Z,{autoplay:!0,children:[(0,l.jsx)("div",{children:(0,l.jsx)("h3",{style:s,children:"1"})}),(0,l.jsx)("div",{children:(0,l.jsx)("h3",{style:s,children:"2"})}),(0,l.jsx)("div",{children:(0,l.jsx)("h3",{style:s,children:"3"})}),(0,l.jsx)("div",{children:(0,l.jsx)("h3",{style:s,children:"4"})})]})}},9121:function(e,i,t){t.r(i),t.d(i,{default:function(){return s}});t(2791),t(876);var n=t(4996),l=t(184);var s=function(){return(0,l.jsxs)("div",{className:"project_container",children:[(0,l.jsx)("div",{className:"project_title",children:"MobileDeepPill: A Small-Footprint Mobile Deep Learning System for Recognizing Unconstrained Pill Images"}),(0,l.jsx)("div",{className:"project_conference",children:"MobiSys'17"}),(0,l.jsx)("div",{className:"project_members",children:"Xiao Zeng, Kai Cao, and Mi Zhang."}),(0,l.jsxs)("div",{className:"project_buttons",children:[(0,l.jsxs)("a",{href:"https://mi-zhang.github.io/papers/2017_MobiSys_MobileDeepPill.pdf",className:"project_button",children:[(0,l.jsx)("svg",{t:"1687728426228",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2399",width:"16",height:"16",children:(0,l.jsx)("path",{d:"M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z",fill:"#ffffff","p-id":"2400"})}),"\xa0Paper"]}),(0,l.jsx)(n.Z,{inproceeding:"@inproceedings{zeng2017mobiledeeppill,",title:"title = {{MobileDeepPill: A Small-Footprint Mobile Deep Learning System for Recognizing Unconstrained Pill Images}},",author:"author = {Zeng, Xiao and Cao, Kai and Zhang, Mi},",booktitle:"booktitle = {Proceedings of the 15th ACM International Conference on Mobile Systems, Applications, and Services (MobiSys)},",pages:"pages = {56--67},",year:"year = {2017},",numpages:"numpages = {12},",address:"address = {Niagara Falls, NY, USA}"})]}),(0,l.jsx)("div",{className:"project_collection",children:(0,l.jsx)("div",{children:(0,l.jsx)("img",{src:"./images/projects/MobileDeepPill_in.svg",alt:"",className:"project_collection_img"})})}),(0,l.jsxs)("div",{className:"project_abstract",children:[(0,l.jsx)("div",{className:"project_abstract_title",children:"Abstract"}),(0,l.jsx)("div",{className:"project_abstract_content",children:"Correct identification of prescription pills based on their visual appearance is a key step required to assure patient safety and facilitate more effective patient care. With the availability of highquality cameras and computational power on smartphones, it is possible and helpful to identify unknown prescription pills using smartphones. Towards this goal, in 2016, the U.S. National Library of Medicine (NLM) of the National Institutes of Health (NIH) announced a nationwide competition, calling for the creation of a mobile vision system that can recognize pills automatically from a mobile phone picture under unconstrained real-world settings. In this paper, we present the design and evaluation of such mobile pill image recognition system called MobileDeepPill. The development of MobileDeepPill involves three key innovations: a triplet loss function which attains invariances to real-world noisiness that deteriorates the quality of pill images taken by mobile phones; a multi-CNNs model that collectively captures the shape, color and imprints characteristics of the pills; and a Knowledge Distillation-based deep model compression framework that significantly reduces the size of the multi-CNNs model without deteriorating its recognition performance. Our deep learning-based pill image recognition algorithm wins the First Prize (champion) of the NIH NLM Pill Image Recognition Challenge. Given its promising performance, we believe MobileDeepPill helps NIH tackle a critical problem with significant societal impact and will benefit millions of healthcare personnel and the general public."})]})]})}},4996:function(e,i,t){t.d(i,{Z:function(){return r}});var n=t(9439),l=t(2791),s=t(6913),a=t(7309),o=t(184),r=function(e){var i=(0,l.useState)(!1),t=(0,n.Z)(i,2),r=t[0],c=t[1],d=function(){c(!1)};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsxs)("button",{href:"",className:"project_button",onClick:function(){c(!0)},children:[(0,o.jsx)("svg",{t:"1687730915571",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2419",width:"16",height:"16",children:(0,o.jsx)("path",{d:"M313.6 170.666667h469.333333c27.733333 0 42.666667 14.933333 42.666667 42.666666v512c0 8.533333-4.266667 17.066667-10.666667 23.466667l-36.266666 36.266667c-2.133333 2.133333-6.4 4.266667-6.4 2.133333-2.133333 0-2.133333-4.266667-2.133334-6.4v-539.733333c0-4.266667-2.133333-6.4-4.266666-10.666667s-6.4-4.266667-10.666667-4.266667h-398.933333c-8.533333 0-17.066667 4.266667-23.466667 10.666667l-36.266667 36.266667c-2.133333 2.133333-4.266667 6.4-2.133333 6.4 0 2.133333 4.266667 2.133333 6.4 2.133333h398.933333c4.266667 0 6.4 2.133333 10.666667 4.266667s4.266667 6.4 4.266667 10.666666v539.733334c0 4.266667-2.133333 6.4-4.266667 10.666666s-6.4 4.266667-10.666667 4.266667H213.333333c-4.266667 0-6.4-2.133333-10.666666-4.266667s-4.266667-6.4-4.266667-10.666666v-554.666667c0-8.533333 4.266667-17.066667 10.666667-23.466667l78.933333-78.933333c6.4-4.266667 14.933333-8.533333 25.6-8.533333z","p-id":"2420",fill:"#ffffff"})}),"\xa0BibTex"]}),(0,o.jsx)(s.Z,{title:"BibTex",open:r,onCancel:d,width:1e3,footer:[(0,o.jsx)(a.ZP,{onClick:d,children:"Return"},"back")],children:(0,o.jsxs)("div",{className:"popModalBG",children:[(0,o.jsx)("p",{children:e.inproceeding}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.title]}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.author]}),e.booktitle&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.booktitle]}),e.journal&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.journal]}),e.volume&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.volume]}),e.number&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.number]}),e.pages&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.pages]}),(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.year]}),e.numpages&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.numpages]}),e.address&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.address]}),e.location&&(0,o.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.location]}),(0,o.jsx)("p",{children:"}"})]})})]})}}}]);
//# sourceMappingURL=121.5be9db29.chunk.js.map