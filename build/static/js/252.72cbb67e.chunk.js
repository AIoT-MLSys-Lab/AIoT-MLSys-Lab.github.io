"use strict";(self.webpackChunklabwebsite=self.webpackChunklabwebsite||[]).push([[252],{876:function(e,n,i){var t=i(8316),s=i(184),a={height:"300px",color:"#fff",lineHeight:"160px",textAlign:"center",background:"#364d79"};n.Z=function(){return(0,s.jsxs)(t.Z,{autoplay:!0,children:[(0,s.jsx)("div",{children:(0,s.jsx)("h3",{style:a,children:"1"})}),(0,s.jsx)("div",{children:(0,s.jsx)("h3",{style:a,children:"2"})}),(0,s.jsx)("div",{children:(0,s.jsx)("h3",{style:a,children:"3"})}),(0,s.jsx)("div",{children:(0,s.jsx)("h3",{style:a,children:"4"})})]})}},2252:function(e,n,i){i.r(n),i.d(n,{default:function(){return a}});i(2791),i(876);var t=i(4996),s=i(184);var a=function(){return(0,s.jsxs)("div",{className:"project_container",children:[(0,s.jsx)("div",{className:"project_title",children:"DeepASL: Enabling Ubiquitous and Non-Intrusive Word and Sentence-Level Sign Language Translation"}),(0,s.jsx)("div",{className:"project_conference",children:"SenSys'17"}),(0,s.jsx)("div",{className:"project_members",children:"Biyi Fang, Jillian Co, and Mi Zhang."}),(0,s.jsxs)("div",{className:"project_buttons",children:[(0,s.jsxs)("a",{href:"https://mi-zhang.github.io/papers/2017_SenSys_DeepASL.pdf",className:"project_button",children:[(0,s.jsx)("svg",{t:"1687728426228",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2399",width:"16",height:"16",children:(0,s.jsx)("path",{d:"M213.34016 0l597.34016 0q53.00224 0 90.50112 37.49888t37.49888 90.50112l0 768q0 53.00224-37.49888 90.50112t-90.50112 37.49888l-597.34016 0q-53.00224 0-90.50112-37.49888t-37.49888-90.50112l0-768q0-53.00224 37.49888-90.50112t90.50112-37.49888zM341.34016 725.34016l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 554.65984l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM810.65984 85.34016l-597.34016 0q-17.67424 0-30.16704 12.4928t-12.4928 30.16704l0 768q0 17.67424 12.4928 30.16704t30.16704 12.4928l597.34016 0q17.67424 0 30.16704-12.4928t12.4928-30.16704l0-768q0-17.67424-12.4928-30.16704t-30.16704-12.4928zM341.34016 384l341.34016 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-341.34016 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928zM341.34016 213.34016l170.65984 0q17.67424 0 30.16704 12.4928t12.4928 30.16704-12.4928 30.16704-30.16704 12.4928l-170.65984 0q-17.67424 0-30.16704-12.4928t-12.4928-30.16704 12.4928-30.16704 30.16704-12.4928z",fill:"#ffffff","p-id":"2400"})}),"\xa0Paper"]}),(0,s.jsx)(t.Z,{inproceeding:"@inproceedings{fang2017deepasl,",title:"title = {{DeepASL: Enabling Ubiquitous and Non-Intrusive Word and Sentence-Level Sign Language Translation}}, ",author:"author = {Fang, Biyi and Co, Jillian and Zhang, Mi},",booktitle:"booktitle = {Proceedings of the 15th ACM Conference on Embedded Networked Sensor Systems (SenSys)},",year:"year = {2017},",address:"address = {Delft, The Netherlands}"})]}),(0,s.jsx)("div",{className:"project_collection",children:(0,s.jsx)("div",{children:(0,s.jsx)("img",{src:"./images/projects/DeepASL_in.svg",alt:"",className:"project_collection_img"})})}),(0,s.jsxs)("div",{className:"project_abstract",children:[(0,s.jsx)("div",{className:"project_abstract_title",children:"Abstract"}),(0,s.jsx)("div",{className:"project_abstract_content",children:"There is an undeniable communication barrier between deaf people and people with normal hearing ability. Although innovations in sign language translation technology aim to tear down this communication barrier, the majority of existing sign language translation systems are either intrusive or constrained by resolution or ambient lighting conditions. Moreover, these existing systems can only perform single-sign ASL translation rather than sentence-level translation, making them much less useful in daily-life communication scenarios. In this work, we fill this critical gap by presenting DeepASL, a transformative deep learning-based sign language translation technology that enables ubiquitous and non-intrusive American Sign Language (ASL) translation at both word and sentence levels. DeepASL uses infrared light as its sensing mechanism to non-intrusively capture the ASL signs. It incorporates a novel hierarchical bidirectional deep recurrent neural network (HB-RNN) and a probabilistic framework based on Connectionist Temporal Classification (CTC) for word-level and sentence-level ASL translation respectively. To evaluate its performance, we have collected 7, 306 samples from 11 participants, covering 56 commonly used ASL words and 100 ASL sentences. DeepASL achieves an average 94.5% word-level translation accuracy and an average 8.2% word error rate on translating unseen ASL sentences. Given its promising performance, we believe DeepASL represents a significant step towards breaking the communication barrier between deaf people and hearing majority, and thus has the significant potential to fundamentally change deaf people\u2019s lives."})]})]})}},4996:function(e,n,i){i.d(n,{Z:function(){return o}});var t=i(9439),s=i(2791),a=i(969),r=i(7309),l=i(184),o=function(e){var n=(0,s.useState)(!1),i=(0,t.Z)(n,2),o=i[0],c=i[1],d=function(){c(!1)};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsxs)("button",{href:"",className:"project_button",onClick:function(){c(!0)},children:[(0,l.jsx)("svg",{t:"1687730915571",class:"icon",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg","p-id":"2419",width:"16",height:"16",children:(0,l.jsx)("path",{d:"M313.6 170.666667h469.333333c27.733333 0 42.666667 14.933333 42.666667 42.666666v512c0 8.533333-4.266667 17.066667-10.666667 23.466667l-36.266666 36.266667c-2.133333 2.133333-6.4 4.266667-6.4 2.133333-2.133333 0-2.133333-4.266667-2.133334-6.4v-539.733333c0-4.266667-2.133333-6.4-4.266666-10.666667s-6.4-4.266667-10.666667-4.266667h-398.933333c-8.533333 0-17.066667 4.266667-23.466667 10.666667l-36.266667 36.266667c-2.133333 2.133333-4.266667 6.4-2.133333 6.4 0 2.133333 4.266667 2.133333 6.4 2.133333h398.933333c4.266667 0 6.4 2.133333 10.666667 4.266667s4.266667 6.4 4.266667 10.666666v539.733334c0 4.266667-2.133333 6.4-4.266667 10.666666s-6.4 4.266667-10.666667 4.266667H213.333333c-4.266667 0-6.4-2.133333-10.666666-4.266667s-4.266667-6.4-4.266667-10.666666v-554.666667c0-8.533333 4.266667-17.066667 10.666667-23.466667l78.933333-78.933333c6.4-4.266667 14.933333-8.533333 25.6-8.533333z","p-id":"2420",fill:"#ffffff"})}),"\xa0BibTex"]}),(0,l.jsx)(a.Z,{title:"BibTex",open:o,onCancel:d,width:1e3,footer:[(0,l.jsx)(r.ZP,{onClick:d,children:"Return"},"back")],children:(0,l.jsxs)("div",{className:"popModalBG",children:[(0,l.jsx)("p",{children:e.inproceeding}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.title]}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.author]}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.booktitle]}),e.pages&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.pages]}),(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.year]}),e.numpages&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.numpages]}),e.address&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.address]}),e.location&&(0,l.jsxs)("p",{children:["\xa0\xa0\xa0\xa0",e.location]}),(0,l.jsx)("p",{children:"}"})]})})]})}}}]);
//# sourceMappingURL=252.72cbb67e.chunk.js.map